#!/bin/bash

# ===================================================
# Complete Model Setup - All Engines
# ===================================================
# Sets up shared volumes and pulls models for:
# - Ollama (LLM)
# - Whisper (Speech-to-Text)
# - Stable Diffusion (Image Generation)
# ===================================================

set -e

echo "ğŸš€ Voke Model Setup - All Engines"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# ===================================================
# 1. OLLAMA MODELS
# ===================================================
echo ""
echo "ğŸ“¦ [1/3] Setting up Ollama Models..."
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

OLLAMA_VOLUME="ollama-models"
OLLAMA_MODELS=(
  "qwen2:0.5b"
)

# Create volume
if docker volume inspect "$OLLAMA_VOLUME" &>/dev/null; then
  echo "âœ… Volume '$OLLAMA_VOLUME' exists"
else
  docker volume create "$OLLAMA_VOLUME"
  echo "âœ… Created volume '$OLLAMA_VOLUME'"
fi

# Pull models
echo "Starting temporary Ollama container..."
docker run -d --name ollama-setup \
  -v "$OLLAMA_VOLUME:/root/.ollama" \
  ollama/ollama

sleep 5

for model in "${OLLAMA_MODELS[@]}"; do
  echo "ğŸ“¥ Pulling $model..."
  docker exec ollama-setup ollama pull "$model" || echo "âš ï¸  Failed to pull $model"
done

docker stop ollama-setup >/dev/null 2>&1
docker rm ollama-setup >/dev/null 2>&1
echo "âœ… Ollama setup complete"

# ===================================================
# 2. WHISPER MODELS
# ===================================================
echo ""
echo "ğŸ¤ [2/3] Setting up Whisper Models..."
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

WHISPER_VOLUME="whisper-models"

# Create volume
if docker volume inspect "$WHISPER_VOLUME" &>/dev/null; then
  echo "âœ… Volume '$WHISPER_VOLUME' exists"
else
  docker volume create "$WHISPER_VOLUME"
  echo "âœ… Created volume '$WHISPER_VOLUME'"
fi

# Pre-download Whisper models using Python
echo "ğŸ“¥ Downloading Whisper models..."
docker run --rm \
  -v "$WHISPER_VOLUME:/models" \
  python:3.11-slim bash -c "
    pip install -q openai-whisper && \
    python -c '
import whisper
import os
os.environ[\"WHISPER_CACHE\"] = \"/models\"
for model in [\"tiny\"]:
    print(f\"Downloading {model}...\")
    whisper.load_model(model, download_root=\"/models\")
    print(f\"âœ… {model} ready\")
'
" || echo "âš ï¸  Whisper setup failed (will download on first use)"

echo "âœ… Whisper setup complete"

# ===================================================
# 3. STABLE DIFFUSION MODELS
# ===================================================
echo ""
echo "ğŸ¨ [3/3] Setting up Stable Diffusion Models..."
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

SD_VOLUME="sd-models"

# Create volume
if docker volume inspect "$SD_VOLUME" &>/dev/null; then
  echo "âœ… Volume '$SD_VOLUME' exists"
else
  docker volume create "$SD_VOLUME"
  echo "âœ… Created volume '$SD_VOLUME'"
fi

# Download SD models (using huggingface-cli)
echo "ğŸ“¥ Downloading Stable Diffusion models..."
docker run --rm \
  -v "$SD_VOLUME:/models" \
  python:3.11-slim bash -c "
    pip install -q huggingface-hub && \
    python -c '
from huggingface_hub import snapshot_download
import os

models = [
    (\"stabilityai/sd-turbo\"),
    (),
]

for repo, name in models:
    try:
        print(f\"ğŸ“¥ Downloading {name}...\")
        snapshot_download(
            repo_id=repo,
            local_dir=f\"/models/{name}\",
            local_dir_use_symlinks=False
        )
        print(f\"âœ… {name} ready\")
    except Exception as e:
        print(f\"âš ï¸  {name} failed: {e}\")
'
" || echo "âš ï¸  SD setup failed (will download on first use)"

echo "âœ… Stable Diffusion setup complete"

# ===================================================
# SUMMARY
# ===================================================
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ‰ All Models Setup Complete!"
echo ""
echo "ğŸ“Š Volume Summary:"
echo "   â€¢ $OLLAMA_VOLUME   - Ollama LLM models"
echo "   â€¢ $WHISPER_VOLUME  - Whisper STT models"
echo "   â€¢ $SD_VOLUME       - Stable Diffusion models"
echo ""
echo "ğŸ’¾ Total Space Used:"
docker system df -v | grep -E "(ollama|whisper|sd)-models" || echo "   Run 'docker system df -v' to check"
echo ""
echo "ğŸ’¡ Next Steps:"
echo "   1. Update services to use these volumes"
echo "   2. Set mount as read-only: 'volume:/path:ro'"
echo "   3. Remove model download logic from code"
echo "   4. Test container creation speed ğŸš€"
echo ""